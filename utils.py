import re
import os
import json
import logging
from typing import List, Dict, Any
from openai import OpenAI

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize OpenAI client for utility functions
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY", "default_key"))

def extract_keywords(text: str, max_keywords: int = 5) -> List[str]:
    """Extract keywords from text using OpenAI"""
    try:
        prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í‚¤ì›Œë“œë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
IT ê¸°ìˆ , ë„êµ¬, ë¬¸ì œ ìœ í˜•, í•´ê²° ë°©ë²•ê³¼ ê´€ë ¨ëœ í‚¤ì›Œë“œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì„ íƒí•´ì£¼ì„¸ìš”.
ìµœëŒ€ {max_keywords}ê°œì˜ í‚¤ì›Œë“œë¥¼ JSON ë°°ì—´ í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸: {text}

ì‘ë‹µ í˜•ì‹: {{"keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", ...]}}
"""
        
        # the newest OpenAI model is "gpt-4o" which was released May 13, 2024.
        # do not change this unless explicitly requested by the user
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        keywords = result.get("keywords", [])
        
        # Clean and validate keywords
        clean_keywords = []
        for keyword in keywords:
            if isinstance(keyword, str) and len(keyword.strip()) > 0:
                clean_keywords.append(keyword.strip())
        
        return clean_keywords[:max_keywords]
        
    except Exception as e:
        logger.error(f"Failed to extract keywords using OpenAI: {e}")
        return _extract_keywords_fallback(text, max_keywords)

def _extract_keywords_fallback(text: str, max_keywords: int = 5) -> List[str]:
    """Fallback keyword extraction using simple text processing"""
    try:
        # Common IT-related keywords to prioritize
        it_keywords = {
            'database', 'db', 'ë°ì´í„°ë² ì´ìŠ¤', 'oracle', 'mysql', 'postgresql',
            'server', 'ì„œë²„', 'cpu', 'memory', 'ë©”ëª¨ë¦¬', 'disk', 'ë””ìŠ¤í¬',
            'network', 'ë„¤íŠ¸ì›Œí¬', 'connection', 'ì—°ê²°', 'error', 'ì—ëŸ¬',
            'performance', 'ì„±ëŠ¥', 'monitoring', 'ëª¨ë‹ˆí„°ë§', 'backup', 'ë°±ì—…',
            'query', 'ì¿¼ë¦¬', 'index', 'ì¸ë±ìŠ¤', 'tablespace', 'í…Œì´ë¸”ìŠ¤í˜ì´ìŠ¤',
            'log', 'ë¡œê·¸', 'session', 'ì„¸ì…˜', 'lock', 'ë½', 'timeout', 'íƒ€ì„ì•„ì›ƒ'
        }
        
        # Simple word extraction
        words = re.findall(r'\b\w+\b', text.lower())
        
        # Filter and score words
        keyword_scores = {}
        for word in words:
            if len(word) > 2:  # Skip very short words
                if word in it_keywords:
                    keyword_scores[word] = keyword_scores.get(word, 0) + 2
                else:
                    keyword_scores[word] = keyword_scores.get(word, 0) + 1
        
        # Sort by score and return top keywords
        sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)
        return [keyword for keyword, score in sorted_keywords[:max_keywords]]
        
    except Exception as e:
        logger.error(f"Fallback keyword extraction failed: {e}")
        return []

def summarize_text(text: str, max_length: int = 200) -> str:
    """Summarize text using OpenAI"""
    try:
        if len(text) <= max_length:
            return text
        
        prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ {max_length}ì ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
í•µì‹¬ ë‚´ìš©ê³¼ í•´ê²° ë°©ë²•ì„ í¬í•¨í•˜ì—¬ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸: {text}
"""
        
        # the newest OpenAI model is "gpt-4o" which was released May 13, 2024.
        # do not change this unless explicitly requested by the user
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=100
        )
        
        summary = response.choices[0].message.content.strip()
        
        # Ensure summary doesn't exceed max_length
        if len(summary) > max_length:
            summary = summary[:max_length-3] + "..."
        
        return summary
        
    except Exception as e:
        logger.error(f"Failed to summarize text using OpenAI: {e}")
        return _summarize_text_fallback(text, max_length)

def _summarize_text_fallback(text: str, max_length: int = 200) -> str:
    """Fallback text summarization using simple truncation"""
    try:
        if len(text) <= max_length:
            return text
        
        # Try to find a good breaking point (sentence end)
        truncated = text[:max_length-3]
        last_period = truncated.rfind('.')
        last_question = truncated.rfind('?')
        last_exclamation = truncated.rfind('!')
        
        break_point = max(last_period, last_question, last_exclamation)
        
        if break_point > max_length // 2:  # If we found a reasonable break point
            return text[:break_point+1]
        else:
            return truncated + "..."
            
    except Exception as e:
        logger.error(f"Fallback text summarization failed: {e}")
        return text[:max_length-3] + "..." if len(text) > max_length else text

def validate_issue_data(title: str, content: str) -> Dict[str, Any]:
    """Validate issue data before saving"""
    errors = []
    warnings = []
    
    # Title validation
    if not title or len(title.strip()) == 0:
        errors.append("ì œëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif len(title) > 500:
        errors.append("ì œëª©ì€ 500ìë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # Content validation
    if not content or len(content.strip()) == 0:
        errors.append("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif len(content) < 10:
        warnings.append("ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë” ìì„¸í•œ ì„¤ëª…ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    elif len(content) > 10000:
        errors.append("ë‚´ìš©ì€ 10,000ìë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return {
        "is_valid": len(errors) == 0,
        "errors": errors,
        "warnings": warnings
    }

def format_issue_card(issue_data: Dict[str, Any]) -> str:
    """Format issue data into a card-like display"""
    try:
        title = issue_data.get("title", "ì œëª© ì—†ìŒ")
        content = issue_data.get("content", "ë‚´ìš© ì—†ìŒ")
        keywords = issue_data.get("keywords", [])
        view_count = issue_data.get("view_count", 0)
        created_at = issue_data.get("created_at", "")
        
        # Create summary if content is too long
        if len(content) > 150:
            summary = summarize_text(content, 150)
        else:
            summary = content
        
        # Format keywords
        keyword_tags = " ".join([f"#{kw}" for kw in keywords]) if keywords else ""
        
        card_html = f"""
        <div class="issue-card">
            <h3 class="issue-title">{title}</h3>
            <p><strong>ìš”ì•½:</strong> {summary}</p>
            <div class="issue-keywords">{keyword_tags}</div>
            <div class="issue-meta">
                <span class="view-count">ì¡°íšŒìˆ˜: {view_count}</span>
                <span class="created-date">{created_at}</span>
            </div>
        </div>
        """
        
        return card_html
        
    except Exception as e:
        logger.error(f"Failed to format issue card: {e}")
        return "<div class='issue-card'>ì¹´ë“œ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.</div>"

def clean_text(text: str) -> str:
    """Clean and normalize text input"""
    if not text:
        return ""
    
    # Remove excessive whitespace
    cleaned = re.sub(r'\s+', ' ', text.strip())
    
    # Remove potentially harmful characters for database
    cleaned = re.sub(r'[<>"\';\\]', '', cleaned)
    
    return cleaned

def generate_search_suggestions(query: str, existing_issues: List[Dict]) -> List[str]:
    """Generate search suggestions based on query and existing issues"""
    try:
        suggestions = []
        
        if not query:
            return suggestions
        
        query_lower = query.lower()
        
        # Find partial matches in titles
        for issue in existing_issues:
            title = issue.get("title", "").lower()
            if query_lower in title and len(suggestions) < 5:
                suggestions.append(issue.get("title", ""))
        
        # Find keyword matches
        for issue in existing_issues:
            keywords = issue.get("keywords", [])
            for keyword in keywords:
                if query_lower in keyword.lower() and len(suggestions) < 5:
                    suggestion = f"#{keyword} ê´€ë ¨ ì´ìŠˆ"
                    if suggestion not in suggestions:
                        suggestions.append(suggestion)
        
        return suggestions[:5]
        
    except Exception as e:
        logger.error(f"Failed to generate search suggestions: {e}")
        return []

def format_chat_message(message: str, is_user: bool = True) -> str:
    """Format chat message for display"""
    try:
        if is_user:
            return f"**ğŸ‘¤ ì‚¬ìš©ì:** {message}"
        else:
            return f"**ğŸ¤– ë¬¼ì–´ë³´SHOO:** {message}"
    except Exception as e:
        logger.error(f"Failed to format chat message: {e}")
        return message

def get_file_size_mb(file_content: str) -> float:
    """Calculate file size in MB"""
    try:
        return len(file_content.encode('utf-8')) / (1024 * 1024)
    except Exception as e:
        logger.error(f"Failed to calculate file size: {e}")
        return 0.0
