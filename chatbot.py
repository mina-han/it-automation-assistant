import os
import json
import logging
from openai import OpenAI
from typing import List, Dict, Any, Tuple

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ChatBot:
    def __init__(self, rag_engine):
        """Initialize ChatBot with RAG engine and OpenAI client"""
        self.rag_engine = rag_engine
        
        # Initialize OpenAI client
        api_key = os.getenv("OPENAI_API_KEY", "default_key")
        self.client = OpenAI(api_key=api_key)
        
        # System prompt for the chatbot
        self.system_prompt = """
ë‹¹ì‹ ì€ IT ì‹¤ë¬´ìë¥¼ ìœ„í•œ ì „ë¬¸ì ì¸ ì´ìŠˆ í•´ê²° ë„ìš°ë¯¸ 'ë¬¼ì–´ë³´SHOO'ì…ë‹ˆë‹¤.

ì—­í• ê³¼ íŠ¹ì§•:
- IT ì¸í”„ë¼, ë°ì´í„°ë² ì´ìŠ¤, ì‹œìŠ¤í…œ ìš´ì˜ ê´€ë ¨ ì§ˆë¬¸ì— ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€
- ê¸°ì¡´ì— í•´ê²°ëœ ìœ ì‚¬í•œ ì´ìŠˆë“¤ì„ ì°¸ê³ í•˜ì—¬ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ í•´ê²°ì±… ì œì‹œ
- í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ë‹µë³€
- ë‹¨ê³„ë³„ë¡œ ëª…í™•í•œ í•´ê²° ë°©ë²• ì œì‹œ

ë‹µë³€ í˜•ì‹:
1. ë¬¸ì œ ìƒí™© ìš”ì•½
2. ê°€ëŠ¥í•œ ì›ì¸ ë¶„ì„
3. í•´ê²° ë°©ë²• (ë‹¨ê³„ë³„)
4. ì˜ˆë°©ì±… ë˜ëŠ” ëª¨ë‹ˆí„°ë§ ë°©ë²•
5. ê´€ë ¨ ìœ ì‚¬ ì´ìŠˆ (ìˆë‹¤ë©´)

ì£¼ì˜ì‚¬í•­:
- ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•˜ë˜, ì¼ë°˜ì ì¸ IT ì§€ì‹ë„ í•¨ê»˜ í™œìš©
- ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ëª…ì‹œì ìœ¼ë¡œ í‘œì‹œ
- ì¤‘ìš”í•œ ì‘ì—…ì˜ ê²½ìš° ë°±ì—…ì´ë‚˜ í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œì˜ ì„ í–‰ í…ŒìŠ¤íŠ¸ë¥¼ ê¶Œì¥
"""
    
    def get_response(self, user_message: str) -> str:
        """Generate response for user message using RAG and LLM"""
        return self.get_response_with_context(user_message, [])
    
    def get_response_with_context(self, user_message: str, conversation_context: list) -> str:
        """Generate response for user message using RAG, LLM and conversation context"""
        try:
            # Get relevant context from RAG engine
            context, related_issues = self.rag_engine.get_context_for_query(user_message)
            
            # Prepare the conversation context
            if related_issues:
                context_prompt = f"""
ê´€ë ¨ ì´ìŠˆ ì •ë³´:
{context}

ìœ„ì˜ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
            else:
                context_prompt = "ê¸°ì¡´ ì´ìŠˆ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ IT ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
            
            # Prepare messages for OpenAI API with conversation history
            messages = [{"role": "system", "content": self.system_prompt}]
            
            # Add previous conversation context (last 5 exchanges)
            for exchange in conversation_context[-5:]:
                messages.append({"role": "user", "content": exchange["user"]})
                messages.append({"role": "assistant", "content": exchange["assistant"]})
            
            # Add current message with context
            messages.append({
                "role": "user", 
                "content": f"{context_prompt}\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_message}"
            })
            
            # the newest OpenAI model is "gpt-4o" which was released May 13, 2024.
            # do not change this unless explicitly requested by the user
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                max_tokens=1500,
                temperature=0.7
            )
            
            bot_response = response.choices[0].message.content
            
            # Add conversation continuity indicator if there's previous context
            if conversation_context:
                bot_response = f"ğŸ’­ *ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ë©° ë‹µë³€ë“œë¦½ë‹ˆë‹¤*\n\n{bot_response}"
            
            # Add related issues information to response if available
            if related_issues:
                bot_response += f"\n\nğŸ“š **ê´€ë ¨ ìœ ì‚¬ ì´ìŠˆë“¤:**\n"
                for issue in related_issues[:3]:  # Show top 3
                    bot_response += f"â€¢ {issue['title']} (ìœ ì‚¬ë„: {issue['similarity']:.0%})\n"
            
            # Save chat interaction to database
            try:
                self.rag_engine.db_manager.save_chat_history(
                    user_message, 
                    bot_response, 
                    related_issues
                )
            except Exception as e:
                logger.warning(f"Failed to save chat history: {e}")
            
            return bot_response
            
        except Exception as e:
            logger.error(f"Failed to generate response: {e}")
            return self._get_fallback_response(user_message)
    
    def _get_fallback_response(self, user_message: str) -> str:
        """Provide fallback response when main system fails"""
        fallback_responses = {
            "database": "ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ë¬¸ì œì˜ ê²½ìš°, ë‹¤ìŒ ì‚¬í•­ë“¤ì„ í™•ì¸í•´ë³´ì„¸ìš”:\n1. ì„œë²„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  í™•ì¸\n2. ìŠ¬ë¡œìš° ì¿¼ë¦¬ ë¡œê·¸ í™•ì¸\n3. ì¸ë±ìŠ¤ ìµœì í™” ê²€í† \n4. ì»¤ë„¥ì…˜ í’€ ì„¤ì • í™•ì¸",
            "server": "ì„œë²„ ê´€ë ¨ ì´ìŠˆì˜ ê²½ìš°:\n1. ì‹œìŠ¤í…œ ë¡œê·¸ í™•ì¸\n2. CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬ ì‚¬ìš©ë¥  í™•ì¸\n3. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸\n4. ì„œë¹„ìŠ¤ í”„ë¡œì„¸ìŠ¤ ìƒíƒœ í™•ì¸",
            "network": "ë„¤íŠ¸ì›Œí¬ ê´€ë ¨ ë¬¸ì œ:\n1. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸\n2. ë°©í™”ë²½ ì„¤ì • í™•ì¸\n3. DNS ì„¤ì • í™•ì¸\n4. í¬íŠ¸ ê°œë°© ìƒíƒœ í™•ì¸"
        }
        
        # Simple keyword matching for fallback
        user_message_lower = user_message.lower()
        
        if any(keyword in user_message_lower for keyword in ['database', 'db', 'ë°ì´í„°ë² ì´ìŠ¤', 'ë””ë¹„']):
            return fallback_responses["database"]
        elif any(keyword in user_message_lower for keyword in ['server', 'ì„œë²„', 'cpu', 'memory', 'ë©”ëª¨ë¦¬']):
            return fallback_responses["server"]
        elif any(keyword in user_message_lower for keyword in ['network', 'ë„¤íŠ¸ì›Œí¬', 'connection', 'ì—°ê²°']):
            return fallback_responses["network"]
        else:
            return """ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì‹œìŠ¤í…œì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆì–´ ì •í™•í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤.

ì¼ë°˜ì ì¸ IT ì´ìŠˆ í•´ê²° ì ‘ê·¼ë²•:
1. **ë¡œê·¸ í™•ì¸**: ì‹œìŠ¤í…œ, ì• í”Œë¦¬ì¼€ì´ì…˜, ì—ëŸ¬ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”
2. **ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§**: CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬, ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ë¥ ì„ í™•ì¸í•˜ì„¸ìš”
3. **ìµœê·¼ ë³€ê²½ì‚¬í•­ ê²€í† **: ìµœê·¼ ì‹œìŠ¤í…œ ë³€ê²½ì´ë‚˜ ì—…ë°ì´íŠ¸ê°€ ìˆì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”
4. **ë‹¨ê³„ì  ì§„ë‹¨**: ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ ì¢í˜€ê°€ë©° ì§„ë‹¨í•˜ì„¸ìš”

ë” êµ¬ì²´ì ì¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì´ìŠˆ ë“±ë¡ì„ í†µí•´ ìƒì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."""
    
    def get_suggested_questions(self) -> List[str]:
        """Get suggested questions based on popular issues"""
        try:
            # Get popular issues from database
            popular_issues = self.rag_engine.db_manager.get_all_issues(sort_option="ì¡°íšŒìˆ˜ ë†’ì€ ìˆœ")
            
            suggestions = []
            for issue in popular_issues[:5]:  # Top 5 popular issues
                issue_id, title, content, keywords, view_count, created_at = issue
                # Create a question based on the issue title
                suggestion = f"{title}ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
                suggestions.append(suggestion)
            
            # Add some general questions if no popular issues
            if not suggestions:
                suggestions = [
                    "ë°ì´í„°ë² ì´ìŠ¤ ì„œë²„ê°€ ëŠë ¤ì§ˆ ë•Œ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
                    "Oracle ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜ í•´ê²° ë°©ë²•ì€?",
                    "ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ì—ì„œ í™•ì¸í•´ì•¼ í•  í•­ëª©ë“¤ì€?",
                    "í…Œì´ë¸”ìŠ¤í˜ì´ìŠ¤ ìš©ëŸ‰ ë¶€ì¡± ë¬¸ì œ í•´ê²°ë²•ì€?",
                    "ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ë° ë³µêµ¬ ì ˆì°¨ëŠ”?"
                ]
            
            return suggestions
            
        except Exception as e:
            logger.error(f"Failed to get suggested questions: {e}")
            return [
                "ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ìµœì í™” ë°©ë²•ì€?",
                "ì‹œìŠ¤í…œ ì¥ì•  ë°œìƒì‹œ ëŒ€ì‘ ì ˆì°¨ëŠ”?",
                "ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì„¤ì • ë°©ë²•ì€?"
            ]
    
    def analyze_user_intent(self, message: str) -> Dict[str, Any]:
        """Analyze user intent and extract key information"""
        try:
            # Use OpenAI to analyze user intent
            analysis_prompt = """
ë‹¤ìŒ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

ë¶„ì„ í•­ëª©:
- intent: ì˜ë„ (ì§ˆë¬¸, ë¬¸ì œí•´ê²°, ì •ë³´ìš”ì²­ ë“±)
- category: ì¹´í…Œê³ ë¦¬ (database, server, network, application ë“±)
- urgency: ê¸´ê¸‰ë„ (low, medium, high)
- keywords: í•µì‹¬ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸

ì‚¬ìš©ì ë©”ì‹œì§€: {message}
""".format(message=message)
            
            # the newest OpenAI model is "gpt-4o" which was released May 13, 2024.
            # do not change this unless explicitly requested by the user
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": analysis_prompt}
                ],
                response_format={"type": "json_object"}
            )
            
            analysis = json.loads(response.choices[0].message.content)
            return analysis
            
        except Exception as e:
            logger.error(f"Failed to analyze user intent: {e}")
            return {
                "intent": "ì§ˆë¬¸",
                "category": "general",
                "urgency": "medium",
                "keywords": []
            }
